<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>EER</title>
      <link href="/2025/01/05/EER/"/>
      <url>/2025/01/05/EER/</url>
      
        <content type="html"><![CDATA[<h1 id="Equal-Error-Rate"><a href="#Equal-Error-Rate" class="headerlink" title="Equal Error Rate"></a>Equal Error Rate</h1><p>EER is defined as the point where the True positive rato (TPR) equals to False positive rato (FPR).<br>In other words, it is the threshold at which the system is equally likely to wrongly accept a non-matching individual as it is to wrongly reject a matching individual. </p><h2 id="Code-Implementation"><a href="#Code-Implementation" class="headerlink" title="Code Implementation"></a>Code Implementation</h2><p><a href="https://github.com/wenet-e2e/wespeaker/blob/master/wespeaker/utils/score_metrics.py#L79">Wespeaker</a></p><h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><ul><li><a href="https://www.cnblogs.com/cdeng/p/3471527.html">https://www.cnblogs.com/cdeng/p/3471527.html</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> Research </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Machine Learning </tag>
            
            <tag> Speaker Verification </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>KL Divergence</title>
      <link href="/2025/01/05/KL_loss/"/>
      <url>/2025/01/05/KL_loss/</url>
      
        <content type="html"><![CDATA[<h1 id="Kullback-Leibler-Divergence"><a href="#Kullback-Leibler-Divergence" class="headerlink" title="Kullback Leibler Divergence"></a>Kullback Leibler Divergence</h1><p><em>KL divergence</em> aims to measure the difference between two probability distributions.<br>The <em>KL divergencel</em> orginates from Information Theory and it is closely related to Information Entropy. </p><h2 id="Information-Entropy"><a href="#Information-Entropy" class="headerlink" title="Information Entropy"></a>Information Entropy</h2><p>The entropy of a random variable quantifies the average level of uncertainty.  If the uncertainty increases, then the information entropy becomes larger. For a probability distribution $p(x)$, entropy is defined :<br>$H(x) &#x3D; -\sum_{x \in X} p(x) \log p(x)$</p><h2 id="KL-divergence"><a href="#KL-divergence" class="headerlink" title="KL divergence"></a>KL divergence</h2><p>The KL divergence is a slight modification of the entropy fomula. Assuming there is a <strong>true</strong> probability distribution $p(x)$ and a predicted distribution $q(x)$, KL divergence is defined as follow:<br>$D_{KL}(p(x)||q(x)) &#x3D; \sum_{x \in X}  p(x) (\log p(x) - \log q(x))$</p><h3 id="Properties"><a href="#Properties" class="headerlink" title="Properties"></a>Properties</h3><ul><li>Non-negativity: $D_{KL} \ge 0$ </li><li>Asymmetry: $D_{KL}(p(x)||q(x)) \ne D_{KL}(q(x)||p(x)) $</li><li>Intuitive: The larger the value of KL divergence, the greater the information loss or error between the true probability and the predicted probability.</li></ul><h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><ul><li><a href="https://www.vectorexplore.com/tech/loss-functions/kl-divergence/">https://www.vectorexplore.com/tech/loss-functions/kl-divergence/</a> </li><li><a href="https://pytorch.org/docs/stable/generated/torch.nn.KLDivLoss.html">https://pytorch.org/docs/stable/generated/torch.nn.KLDivLoss.html</a></li><li><a href="https://blog.csdn.net/qq_50001789/article/details/128974654">https://blog.csdn.net/qq_50001789/article/details/128974654</a></li><li><a href="https://hanj.cs.illinois.edu/cs412/bk3/KL-divergence.pdf">https://hanj.cs.illinois.edu/cs412/bk3/KL-divergence.pdf</a></li><li><a href="https://pytorch.org/docs/stable/generated/torch.nn.functional.kl_div.html">https://pytorch.org/docs/stable/generated/torch.nn.functional.kl_div.html</a> </li><li><a href="https://blog.csdn.net/jinyi763776890/article/details/131178144">https://blog.csdn.net/jinyi763776890/article/details/131178144</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> Research </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Machine Learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hello World!</title>
      <link href="/2025/01/05/hello-world/"/>
      <url>/2025/01/05/hello-world/</url>
      
        <content type="html"><![CDATA[<div class="hbe hbe-container" id="hexo-blog-encrypt" data-wpm="Sorry, the password is uncorrect." data-whm="OOPS, these decrypted content may changed, but you can still have a look.">  <script id="hbeData" type="hbeData" data-hmacdigest="7d77d8dfebcf440042cbc9b23bc8236809a1e6ab746a3677018ef2b0ca09a036">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</script>  <div class="hbe hbe-content">    <div class="hbe hbe-input hbe-input-default">      <input class="hbe hbe-input-field hbe-input-field-default" type="password" id="hbePass">      <label class="hbe hbe-input-label hbe-input-label-default" for="hbePass">        <span class="hbe hbe-input-label-content hbe-input-label-content-default">Password is required to check this post.</span>      </label>    </div>  </div></div><script data-pjax src="/lib/hbe.js"></script><link href="/css/hbe.style.css" rel="stylesheet" type="text/css">]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>min DCF</title>
      <link href="/2025/01/05/min_DCF/"/>
      <url>/2025/01/05/min_DCF/</url>
      
        <content type="html"><![CDATA[<h1 id="minimum-Detection-Cost-Function"><a href="#minimum-Detection-Cost-Function" class="headerlink" title="minimum Detection Cost Function"></a>minimum Detection Cost Function</h1><p>The minDCF is a more comprehensive metric that takes into account the costs associated with different types of errors (false acceptances and false rejections) and the prior probabilities of the classes (target vs. non-target speakers).<br>For example, in a military system, we want the system to be stricter and not to mistakenly allow a person to pass.</p><h2 id="Code-Implementation"><a href="#Code-Implementation" class="headerlink" title="Code Implementation"></a>Code Implementation</h2><p><a href="https://github.com/wenet-e2e/wespeaker/blob/master/wespeaker/utils/score_metrics.py#L96">Wespeaker</a></p><h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><ul><li><a href="https://blog.csdn.net/weixin_41126303/article/details/114293441">https://blog.csdn.net/weixin_41126303/article/details/114293441</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> Research </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Machine Learning </tag>
            
            <tag> Speaker Verification </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Bayes theorm</title>
      <link href="/2025/01/05/Bayes_theorem/"/>
      <url>/2025/01/05/Bayes_theorem/</url>
      
        <content type="html"><![CDATA[<h1 id="Bayes-theorem"><a href="#Bayes-theorem" class="headerlink" title="Bayes theorem"></a>Bayes theorem</h1><p>Bayes‚Äô theorem allows us to update a probability of a hypothesis based on new evidences.<br>The theorem is expressed mathematically as:</p><p>$P(H|E) &#x3D; \frac{P(E|H)* P(H)}{P(E)}$,</p><p>where H denotes the hypothesis, E denotes the evidence.<br>$P(H|E)$: Posterior probablity<br>$P(H)$: Prior probability<br>$P(E|H)$: Likelihood<br>$P(E)$: marginal probability</p><h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><ul><li><a href="https://www.freecodecamp.org/news/bayes-rule-explained/">https://www.freecodecamp.org/news/bayes-rule-explained/</a></li><li><a href="https://liaoxuefeng.com/blogs/all/2023-08-27-bayes-explain/index.html">https://liaoxuefeng.com/blogs/all/2023-08-27-bayes-explain/index.html</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> Research </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Machine Learning </tag>
            
            <tag> Speaker Verification </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>awesome_speaker</title>
      <link href="/2024/09/26/awesome_speaker/"/>
      <url>/2024/09/26/awesome_speaker/</url>
      
        <content type="html"><![CDATA[<h1 id="Awesome-Speaker-In-Speech-Field"><a href="#Awesome-Speaker-In-Speech-Field" class="headerlink" title="Awesome Speaker In Speech Field"></a>Awesome Speaker In Speech Field</h1><blockquote><p>Hi, everyone! I‚Äôm Junjie Li <a href="https://mrjunjieli.github.io/">[Homepage]</a>, currently a Ph.D. student at Hong Kong Polytechnic University (PolyU) üá≠üá∞.<br>This repository aims to help students become familiar with speaker-related tasks while also serving as a resource for my own learning and development. </p></blockquote><p>Summary of speaker related tasks, like speaker recognition, verification, diarization, spoofing, privacy, voice conversion, target speaker extraction and so on. </p><h2 id="Book-recommendations"><a href="#Book-recommendations" class="headerlink" title="Book recommendations"></a>Book recommendations</h2><ul><li>Understanding Deep learning <a href="https://udlbook.github.io/udlbook/">[pdf]</a></li><li>Computer vision: models learning and inference <a href="https://udlbook.github.io/cvbook/">[pdf]</a></li><li>Ê∑±ÂÖ•ÊµÖÂá∫Âº∫ÂåñÂ≠¶‰π†ÔºöÂéüÁêÜÂÖ•Èó® <a href="https://github.com/borninfreedom/DeepLearning/blob/master/Books/%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%EF%BC%9A%E5%8E%9F%E7%90%86%E5%85%A5%E9%97%A8.pdf">[pdf]</a></li><li>Reinforcement Learning <a href="http://incompleteideas.net/book/RLbook2018.pdf">[pdf]</a></li></ul><h2 id="Speaker-Recognition-Verification"><a href="#Speaker-Recognition-Verification" class="headerlink" title="Speaker Recognition&#x2F;Verification:"></a>Speaker Recognition&#x2F;Verification:</h2><h3 id="Toolkit"><a href="#Toolkit" class="headerlink" title="Toolkit"></a>Toolkit</h3><ul><li><a href="https://github.com/wenet-e2e/wespeaker">Wespeaker</a></li></ul><h3 id="Speaker-Models"><a href="#Speaker-Models" class="headerlink" title="Speaker Models"></a>Speaker Models</h3><ul><li>overview: <ul><li>Overview of Speaker Modeling and Its Applications: From the Lens of Deep Speaker Representation Learning</li></ul></li><li>i-vector </li><li>d-vector (frame-level): Deep neural networks for small footprint textdependent speaker verification</li><li>x-vector (segment-level): <ul><li>X-vectors: Robust dnn embeddings for speaker recognition</li><li>Deep Neural Network Embeddings for Text-Independent Speaker Verification</li><li>ECAPA-TDNN: Emphasized Channel Attention, Propagation and Aggregation in TDNN Based Speaker Verification</li></ul></li><li>r-vector: But system description to voxceleb speaker recognition challenge 2019</li><li>xi-vector: Xi-Vector Embedding for Speaker Recognition</li><li>Transformer based: <ul><li>Self Multi-Head Attention for Speaker Recognition</li><li>LOCAL INFORMATION MODELING WITH SELF-ATTENTION FOR SPEAKER VERIFICATION</li></ul></li><li>SPEAKER RECOGNITION FROM RAW WAVEFORM WITH SINCNET </li><li>Self-supervised: <ul><li>Self-supervised speaker embeddings </li><li>Neural Predictive Coding using Convolutional Neural Networks towards Unsupervised Learning of Speaker Characteristics</li></ul></li><li>PLDA: Probabilistic Linear Discriminant Analysis for Inferences About Identity </li><li>Reshape Dimensions Network for Speaker Recognition</li><li>Guided Speaker Embedding</li><li></li></ul><h3 id="Aggregation-Layers"><a href="#Aggregation-Layers" class="headerlink" title="Aggregation Layers"></a>Aggregation Layers</h3><p> implementation: wespeaker&#x2F;models&#x2F;pooling_layers</p><ul><li>Temporal Average Pooling (TAP)</li><li>Temporal Statistics Pooling (TSTP): X-vectors: Robust dnn embeddings for speaker recognition</li><li>Attentive Statistics Pooling (ASP): ECAPA-TDNN: Emphasized Channel Attention, Propagation and Aggregation in TDNN Based Speaker Verification</li></ul><h3 id="Datasets"><a href="#Datasets" class="headerlink" title="Datasets"></a>Datasets</h3><ul><li>Voxceleb1 </li><li>Voxceleb2 </li><li></li></ul><h3 id="Challenge"><a href="#Challenge" class="headerlink" title="Challenge"></a>Challenge</h3><ul><li><a href="https://sre.nist.gov/#tab_home">NIST SRE</a></li></ul><h2 id="Voice-Conversion"><a href="#Voice-Conversion" class="headerlink" title="Voice Conversion"></a>Voice Conversion</h2><h3 id="Non-parallel"><a href="#Non-parallel" class="headerlink" title="Non-parallel:"></a>Non-parallel:</h3><ul><li>CycleGAN-VC: Non-parallel Voice Conversion Using Cycle-Consistent Adversarial Networks</li></ul><h3 id="Voice-Anonymization"><a href="#Voice-Anonymization" class="headerlink" title="Voice Anonymization"></a>Voice Anonymization</h3><ul><li>MODELING PSEUDO-SPEAKER UNCERTAINTY IN VOICE ANONYMIZATION</li></ul><h2 id="Target-Speaker-Extraction"><a href="#Target-Speaker-Extraction" class="headerlink" title="Target Speaker Extraction"></a>Target Speaker Extraction</h2><ul><li>INVESTIGATION OF SPEAKER REPRESENTATION FOR TARGET-SPEAKER SPEECH PROCESSING</li><li></li></ul><h2 id="Speaker-Diarization"><a href="#Speaker-Diarization" class="headerlink" title="Speaker Diarization"></a>Speaker Diarization</h2><h2 id="Spoofing"><a href="#Spoofing" class="headerlink" title="Spoofing"></a>Spoofing</h2><ul><li>Towards Quantifying and Reducing Language Mismatch Effects in Cross-Lingual Speech Anti-Spoofing</li></ul><h2 id="Targer-Speaker-ASR"><a href="#Targer-Speaker-ASR" class="headerlink" title="Targer Speaker ASR"></a>Targer Speaker ASR</h2><h2 id="Personalized-VAD"><a href="#Personalized-VAD" class="headerlink" title="Personalized VAD"></a>Personalized VAD</h2><h2 id="Others"><a href="#Others" class="headerlink" title="Others"></a>Others</h2><ul><li>Emerging Properties in Self-Supervised Vision Transformers</li></ul>]]></content>
      
      
      <categories>
          
          <category> Research </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Speaker Verification </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
